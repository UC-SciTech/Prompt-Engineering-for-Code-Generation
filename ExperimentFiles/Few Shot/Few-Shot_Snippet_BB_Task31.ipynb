{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d52881",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center;'> Technology Capstone Research Project PG (11522) </h2>\n",
    "<h3 style='text-align: center;'> Project ID: 2024-S1-50 </h3>\n",
    "<h3 style='text-align: center;'> Group ID: 11522-24S1-41 </h3>\n",
    "<h4 style='text-align: center;'> Member: MD Alvee Rohan - U3235512 </h4>\n",
    "<h4 style='text-align: center;'> Prompt Technique: Few Shot </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacd8f1",
   "metadata": {},
   "source": [
    "### Revised Prompt for Few Shot\n",
    "\n",
    "### BIG-bench\\\\ c31\n",
    "\n",
    "Write a python code snippet without using a function or function definition  that takes a list of natural numbers and returns a dictionary where the keys are unique elements from the list, and the values are the number of times each element appears, in the order they first appear in the list.\n",
    "\n",
    "Example:\n",
    "\"\"input\"\": \"\"[41, 65, 65, 65, 41]\"\",\n",
    "\"\"target\"\": \"\"[2, 3]\"\"\n",
    "\n",
    " \"\"input\"\": \"\"[12, 12, 12, 12, 12, 12]\"\",\n",
    "\"\"target\"\": \"\"[6]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "738241df-b250-4ddd-95d7-e4d2a6ce0ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7]\n",
      "The element that appears only once is: [9, 7]\n",
      "Execution time: 0.0009970664978027344 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 1\n",
    "# Sample 1\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol1_output1 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model1 = [9, 7, 9, 9]\n",
    "\n",
    "while len(numbers_model1) >= 4 and (numbers_model1[:2] == numbers_model1[-2:] or numbers_model1[0] == numbers_model1[1] or numbers_model1[-1] == numbers_model1[-2]):\n",
    "    if numbers_model1[:2] == numbers_model1[-2:]:\n",
    "        numbers_model1 = numbers_model1[2:-2]\n",
    "    elif numbers_model1[0] == numbers_model1[1]:\n",
    "        numbers_model1 = numbers_model1[2:]\n",
    "    elif numbers_model1[-1] == numbers_model1[-2]:\n",
    "        numbers_model1 = numbers_model1[:-2]\n",
    "\n",
    "print(numbers_model1)\n",
    "\n",
    "# Record the ending time\n",
    "end_time_mol1_output1 = time.time()\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model1)\n",
    "mod1_output1 = numbers_model1\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod1_output1 = end_time_mol1_output1 - start_time_mol1_output1\n",
    "print(f\"Execution time: {execution_time_mod1_output1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adbc0183-6dee-4eb9-a2ae-812a609ee28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 0, 2, 9]\n",
      "The element that appears only once is: [7, 5, 0, 2, 9]\n",
      "Execution time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 1\n",
    "# Sample 2\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol1_output2 = time.time()\n",
    "\n",
    "numbers_model2 = [6, 6, 7, 5, 0, 2, 9]\n",
    "\n",
    "while len(numbers_model2) >= 4 and (numbers_model2[:2] == numbers_model2[-2:] or numbers_model2[0] == numbers_model2[1] or numbers_model2[-1] == numbers_model2[-2]):\n",
    "    if numbers_model2[:2] == numbers_model2[-2:]:\n",
    "        numbers_model2 = numbers_model2[2:-2]\n",
    "    elif numbers_model2[0] == numbers_model2[1]:\n",
    "        numbers_model2 = numbers_model2[2:]\n",
    "    elif numbers_model2[-1] == numbers_model2[-2]:\n",
    "        numbers_model2 = numbers_model2[:-2]\n",
    "\n",
    "print(numbers_model2)\n",
    "\n",
    "# Record the ending time\n",
    "end_time_mol1_output2 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model2)\n",
    "mod1_output2 = numbers_model2\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod1_output2 = end_time_mol1_output2 - start_time_mol1_output2\n",
    "print(f\"Execution time: {execution_time_mod1_output2} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7f07eb9-356f-44ca-8e1f-30121ddd0599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4]\n",
      "The element that appears only once is: [8, 4]\n",
      "Execution time: 0.0009970664978027344 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 1\n",
    "# Sample 3\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol1_output3 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model3 = [8, 4, 4, 4]\n",
    "\n",
    "while len(numbers_model3) >= 4 and (numbers_model3[:2] == numbers_model3[-2:] or numbers_model3[0] == numbers_model3[1] or numbers_model3[-1] == numbers_model3[-2]):\n",
    "    if numbers_model3[:2] == numbers_model3[-2:]:\n",
    "        numbers_model3 = numbers_model3[2:-2]\n",
    "    elif numbers_model3[0] == numbers_model3[1]:\n",
    "        numbers_model3 = numbers_model3[2:]\n",
    "    elif numbers_model3[-1] == numbers_model3[-2]:\n",
    "        numbers_model3 = numbers_model3[:-2]\n",
    "\n",
    "print(numbers_model3)\n",
    "\n",
    "# Record the ending time\n",
    "end_time_mol1_output3 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model3)\n",
    "mod1_output3 = result\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod1_output3 = end_time_mol1_output3 - start_time_mol1_output1\n",
    "print(f\"Execution time: {execution_time_mod1_output1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5be04581-0430-4ed8-a267-dd8f45e87d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output:  [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
      "Actual Output:  [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
      "                 Precision  Recall  F1 Score  Accuracy  Exact Match\n",
      "0                      1.0     1.0       1.0       1.0          1.0\n",
      "1                      1.0     1.0       1.0       1.0          1.0\n",
      "2                      1.0     1.0       1.0       1.0          1.0\n",
      "Model 1 Average        1.0     1.0       1.0       1.0          1.0\n"
     ]
    }
   ],
   "source": [
    "## Model 1 summary\n",
    "\n",
    "import pandas as pd\n",
    "def evaluate_list_metrics(expected_output, actual_output):\n",
    "    exact_match_accuracy = 1 if expected_output == actual_output else 0\n",
    "\n",
    "    # Calculate true positives\n",
    "    true_positives = sum(1 for i in range(min(len(expected_output), len(actual_output))) if expected_output[i] == actual_output[i])\n",
    "\n",
    "    # Calculate false positives\n",
    "    false_positives = sum(1 for i in range(len(actual_output)) if actual_output[i] not in expected_output)\n",
    "\n",
    "    # Calculate false negatives\n",
    "    false_negatives = sum(1 for i in range(len(expected_output)) if expected_output[i] != actual_output[i])\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(1 for i in range(len(expected_output)) if expected_output[i] == actual_output[i]) / max(len(expected_output), len(actual_output))\n",
    "\n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1_score,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Exact Match\": exact_match_accuracy\n",
    "    }\n",
    "\n",
    "expected_outputs = [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
    "actual_outputs_mod1 = [mod1_output1, mod1_output2, mod1_output3]\n",
    "print(\"Expected Output: \", expected_outputs)\n",
    "print(\"Actual Output: \", actual_outputs_mod1)\n",
    "\n",
    "metrics1 = [evaluate_list_metrics(expected, actual) for expected, actual in zip(expected_outputs, actual_outputs_mod1)]\n",
    "\n",
    "# Create DataFrame directly from the list of dictionaries\n",
    "df_metrics1_new = pd.DataFrame(metrics1)\n",
    "\n",
    "# Calculate the average for precision, recall, F1 score, accuracy, and exact match\n",
    "avg_metrics1 = df_metrics1_new.mean(axis=0)\n",
    "avg_metrics1.name = 'Model 1 Average'\n",
    "\n",
    "# # Append the average row to the DataFrame\n",
    "# df_metrics1_new = df_metrics1_new.append(avg_metrics1)\n",
    "\n",
    "# Concatenate the average row to the DataFrame\n",
    "df_metrics1_new = pd.concat([df_metrics1_new, avg_metrics1.to_frame().transpose()])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(df_metrics1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28c3854c-abda-47e6-afb2-80f47c0a07a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7]\n",
      "The element that appears only once is: [9, 7]\n",
      "Execution time: 0.0009970664978027344 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 2\n",
    "# Sample 1\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol2_output1 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model1 = [9, 7, 9, 9]\n",
    "\n",
    "while len(numbers_model1) >= 4:\n",
    "    if numbers_model1[:2] == numbers_model1[-2:]:\n",
    "        numbers_model1 = numbers_model1[2:-2]\n",
    "    elif numbers_model1[0] == numbers_model1[1]:\n",
    "        numbers_model1 = numbers_model1[2:]\n",
    "    elif numbers_model1[-1] == numbers_model1[-2]:\n",
    "        numbers_model1 = numbers_model1[:-2]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(numbers_model1)\n",
    "# Record the ending time\n",
    "end_time_mol2_output1 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model1)\n",
    "mod2_output1 = numbers_model1\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod1_output1 = end_time_mol1_output1 - start_time_mol1_output1\n",
    "print(f\"Execution time: {execution_time_mod1_output1} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be23122d-4011-4446-a7ad-932022c48e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 0, 2, 9]\n",
      "The element that appears only once is: [7, 5, 0, 2, 9]\n",
      "Execution time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 2\n",
    "# Sample 2\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol2_output2 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model2 = [6, 6, 7, 5, 0, 2, 9]\n",
    "\n",
    "while len(numbers_model2) >= 4:\n",
    "    if numbers_model2[:2] == numbers_model2[-2:]:\n",
    "        numbers_model2 = numbers_model2[2:-2]\n",
    "    elif numbers_model2[0] == numbers_model2[1]:\n",
    "        numbers_model2 = numbers_model2[2:]\n",
    "    elif numbers_model2[-1] == numbers_model2[-2]:\n",
    "        numbers_model2 = numbers_model2[:-2]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(numbers_model2)\n",
    "# Record the ending time\n",
    "end_time_mol2_output2 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model2)\n",
    "mod2_output2 = numbers_model2\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod2_output2 = end_time_mol2_output2 - start_time_mol2_output2\n",
    "print(f\"Execution time: {execution_time_mod2_output2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01b38ccb-a583-4477-a002-1b91a218b68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4]\n",
      "The element that appears only once is: [8, 4]\n",
      "Execution time: 43.344032764434814 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 2\n",
    "# Sample 3\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol2_output3 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model3 = [8, 4, 4, 4]\n",
    "\n",
    "while len(numbers_model3) >= 4:\n",
    "    if numbers_model3[:2] == numbers_model3[-2:]:\n",
    "        numbers_model3 = numbers_model3[2:-2]\n",
    "    elif numbers_model3[0] == numbers_model3[1]:\n",
    "        numbers_model3 = numbers_model3[2:]\n",
    "    elif numbers_model3[-1] == numbers_model3[-2]:\n",
    "        numbers_model3 = numbers_model3[:-2]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(numbers_model3)\n",
    "# Record the ending time\n",
    "end_time_mol2_output3 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model3)\n",
    "mod2_output3 = numbers_model3\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod2_output3 = end_time_mol2_output3 - start_time_mol2_output3\n",
    "print(f\"Execution time: {execution_time_mod1_output3} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8349b3cc-5882-4ca9-982d-3857a3003d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output:  [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
      "Actual Output:  [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
      "                 Precision  Recall  F1 Score  Accuracy  Exact Match\n",
      "0                      1.0     1.0       1.0       1.0          1.0\n",
      "1                      1.0     1.0       1.0       1.0          1.0\n",
      "2                      1.0     1.0       1.0       1.0          1.0\n",
      "Model 1 Average        1.0     1.0       1.0       1.0          1.0\n"
     ]
    }
   ],
   "source": [
    "## Model 2 summary\n",
    "import pandas as pd\n",
    "def evaluate_list_metrics(expected_output, actual_output):\n",
    "    exact_match_accuracy = 1 if expected_output == actual_output else 0\n",
    "\n",
    "    # Calculate true positives\n",
    "    true_positives = sum(1 for i in range(min(len(expected_output), len(actual_output))) if expected_output[i] == actual_output[i])\n",
    "\n",
    "    # Calculate false positives\n",
    "    false_positives = sum(1 for i in range(len(actual_output)) if actual_output[i] not in expected_output)\n",
    "\n",
    "    # Calculate false negatives\n",
    "    false_negatives = sum(1 for i in range(len(expected_output)) if expected_output[i] != actual_output[i])\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(1 for i in range(len(expected_output)) if expected_output[i] == actual_output[i]) / max(len(expected_output), len(actual_output))\n",
    "\n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1_score,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Exact Match\": exact_match_accuracy\n",
    "    }\n",
    "\n",
    "expected_outputs = [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
    "actual_outputs_mod2 = [mod2_output1, mod2_output2, mod2_output3]\n",
    "print(\"Expected Output: \", expected_outputs)\n",
    "print(\"Actual Output: \", actual_outputs_mod1)\n",
    "\n",
    "metrics1 = [evaluate_list_metrics(expected, actual) for expected, actual in zip(expected_outputs, actual_outputs_mod1)]\n",
    "\n",
    "# Create DataFrame directly from the list of dictionaries\n",
    "df_metrics1_new = pd.DataFrame(metrics1)\n",
    "\n",
    "# Calculate the average for precision, recall, F1 score, accuracy, and exact match\n",
    "avg_metrics1 = df_metrics1_new.mean(axis=0)\n",
    "avg_metrics1.name = 'Model 1 Average'\n",
    "\n",
    "# # Append the average row to the DataFrame\n",
    "# df_metrics1_new = df_metrics1_new.append(avg_metrics1)\n",
    "\n",
    "# Concatenate the average row to the DataFrame\n",
    "df_metrics1_new = pd.concat([df_metrics1_new, avg_metrics1.to_frame().transpose()])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(df_metrics1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df0dc41c-c8ef-4c91-9163-d20e71bcd610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7]\n",
      "The element that appears only once is: [9, 7, 9, 9]\n",
      "Execution time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 3\n",
    "# Sample 1\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol3_output1 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model1 = [9, 7, 9, 9]\n",
    "\n",
    "def remove_equal_pairs(numbers_model1):\n",
    "    while len(numbers_model1) >= 4 and (numbers_model1[:2] == numbers_model1[-2:] or numbers_model1[0] == numbers_model1[1] or numbers_model1[-1] == numbers_model1[-2]):\n",
    "        if numbers_model1[:2] == numbers_model1[-2:]:\n",
    "            numbers_model1 = numbers_model1[2:-2]\n",
    "        elif numbers_model1[0] == numbers_model1[1]:\n",
    "            numbers_model1 = numbers_model1[2:]\n",
    "        elif numbers_model1[-1] == numbers_model1[-2]:\n",
    "            numbers_model1 = numbers_model1[:-2]\n",
    "    return numbers_model1\n",
    "\n",
    "result1 = remove_equal_pairs(numbers_model1)\n",
    "print(result1)\n",
    "\n",
    "# Record the ending time\n",
    "end_time_mol3_output1 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model1)\n",
    "mod3_output1 = result1\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod3_output1 = end_time_mol3_output1 - start_time_mol3_output1\n",
    "print(f\"Execution time: {execution_time_mod3_output1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1fba973-fe4f-451c-80fe-403a306996a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 0, 2, 9]\n",
      "The element that appears only once is: [6, 6, 7, 5, 0, 2, 9]\n",
      "Execution time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 3\n",
    "# Sample 2\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol3_output2 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model2 = [6, 6, 7, 5, 0, 2, 9]\n",
    "\n",
    "def remove_equal_pairs(numbers_model2):\n",
    "    while len(numbers_model2) >= 4 and (numbers_model2[:2] == numbers_model2[-2:] or numbers_model2[0] == numbers_model2[1] or numbers_model2[-1] == numbers_model2[-2]):\n",
    "        if numbers_model2[:2] == numbers_model2[-2:]:\n",
    "            numbers_model2 = numbers_model2[2:-2]\n",
    "        elif numbers_model2[0] == numbers_model2[1]:\n",
    "            numbers_model2 = numbers_model2[2:]\n",
    "        elif numbers_model2[-1] == numbers_model2[-2]:\n",
    "            numbers_model2 = numbers_model2[:-2]\n",
    "    return numbers_model2\n",
    "\n",
    "result2 = remove_equal_pairs(numbers_model2)\n",
    "print(result2)\n",
    "\n",
    "# Record the ending time\n",
    "end_time_mol3_output2 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model2)\n",
    "mod3_output2 = result2\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod3_output2 = end_time_mol1_output2 - start_time_mol1_output2\n",
    "print(f\"Execution time: {execution_time_mod1_output2} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee658896-85f1-44fe-9213-491a832eebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4]\n",
      "The element that appears only once is: [8, 4, 4, 4]\n",
      "Execution time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Task ID: BIG-bench/c31\n",
    "# Code Snippet - FS\n",
    "# Model 3\n",
    "# Sample 3\n",
    "\n",
    "import time\n",
    "\n",
    "# Record the starting time\n",
    "start_time_mol3_output3 = time.time()\n",
    "\n",
    "# Input list of natural numbers\n",
    "numbers_model3 = [8, 4, 4, 4]\n",
    "\n",
    "def remove_equal_pairs(numbers_model3):\n",
    "    while len(numbers_model3) >= 4 and (numbers_model3[:2] == numbers_model3[-2:] or numbers_model3[0] == numbers_model3[1] or numbers_model3[-1] == numbers_model3[-2]):\n",
    "        if numbers_model3[:2] == numbers_model3[-2:]:\n",
    "            numbers_model3 = numbers_model3[2:-2]\n",
    "        elif numbers_model3[0] == numbers_model3[1]:\n",
    "            numbers_model3 = numbers_model3[2:]\n",
    "        elif numbers_model3[-1] == numbers_model3[-2]:\n",
    "            numbers_model3 = numbers_model3[:-2]\n",
    "    return numbers_model3\n",
    "\n",
    "result3 = remove_equal_pairs(numbers_model3)\n",
    "print(result3)\n",
    "# Record the ending time\n",
    "end_time_mol3_output3 = time.time()\n",
    "\n",
    "# Print the result\n",
    "print(\"The element that appears only once is:\", numbers_model3)\n",
    "mod3_output3 = result3\n",
    "\n",
    "# Calculate and print the execution time\n",
    "execution_time_mod3_output3 = end_time_mol3_output3 - start_time_mol3_output3\n",
    "print(f\"Execution time: {execution_time_mod3_output3} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc2c06ad-9dab-45da-a867-ef1935eb87ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output:  [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
      "Actual Output:  [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
      "                 Precision  Recall  F1 Score  Accuracy  Exact Match\n",
      "0                      1.0     1.0       1.0       1.0          1.0\n",
      "1                      1.0     1.0       1.0       1.0          1.0\n",
      "2                      1.0     1.0       1.0       1.0          1.0\n",
      "Model 1 Average        1.0     1.0       1.0       1.0          1.0\n"
     ]
    }
   ],
   "source": [
    "## Model 3 summary\n",
    "import pandas as pd\n",
    "def evaluate_list_metrics(expected_output, actual_output):\n",
    "    exact_match_accuracy = 1 if expected_output == actual_output else 0\n",
    "\n",
    "    # Calculate true positives\n",
    "    true_positives = sum(1 for i in range(min(len(expected_output), len(actual_output))) if expected_output[i] == actual_output[i])\n",
    "\n",
    "    # Calculate false positives\n",
    "    false_positives = sum(1 for i in range(len(actual_output)) if actual_output[i] not in expected_output)\n",
    "\n",
    "    # Calculate false negatives\n",
    "    false_negatives = sum(1 for i in range(len(expected_output)) if expected_output[i] != actual_output[i])\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(1 for i in range(len(expected_output)) if expected_output[i] == actual_output[i]) / max(len(expected_output), len(actual_output))\n",
    "\n",
    "    return {\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1_score,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Exact Match\": exact_match_accuracy\n",
    "    }\n",
    "\n",
    "expected_outputs = [[9, 7], [7, 5, 0, 2, 9], [8, 4]]\n",
    "actual_outputs_mod3 = [mod3_output1, mod3_output2, mod3_output3]\n",
    "print(\"Expected Output: \", expected_outputs)\n",
    "print(\"Actual Output: \", actual_outputs_mod1)\n",
    "\n",
    "metrics1 = [evaluate_list_metrics(expected, actual) for expected, actual in zip(expected_outputs, actual_outputs_mod1)]\n",
    "\n",
    "# Create DataFrame directly from the list of dictionaries\n",
    "df_metrics1_new = pd.DataFrame(metrics1)\n",
    "\n",
    "# Calculate the average for precision, recall, F1 score, accuracy, and exact match\n",
    "avg_metrics1 = df_metrics1_new.mean(axis=0)\n",
    "avg_metrics1.name = 'Model 1 Average'\n",
    "\n",
    "# # Append the average row to the DataFrame\n",
    "# df_metrics1_new = df_metrics1_new.append(avg_metrics1)\n",
    "\n",
    "# Concatenate the average row to the DataFrame\n",
    "df_metrics1_new = pd.concat([df_metrics1_new, avg_metrics1.to_frame().transpose()])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(df_metrics1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c43855-aba1-4f76-a67e-9d5792cf88ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
